# ğŸµ ë…¸ë˜ ê°€ì‚¬ ì‹±í¬ í”„ë¡œì íŠ¸ - ê¸°ìˆ  ìµœì‹  ì •ë³´ ì¢…í•© (2025ë…„ 12ì›”)

## ğŸ“‹ ëª©ì°¨
1. [stable-ts (stable-whisper)](#1-stable-ts-stable-whisper)
2. [Whisper ëª¨ë¸ ê³„ì—´](#2-whisper-ëª¨ë¸-ê³„ì—´)
3. [faster-whisper](#3-faster-whisper)
4. [PyTorch & CUDA](#4-pytorch--cuda)
5. [Demucs (ë³´ì»¬ ë¶„ë¦¬)](#5-demucs-ë³´ì»¬-ë¶„ë¦¬)
6. [LRC íŒŒì¼ í¬ë§·](#6-lrc-íŒŒì¼-í¬ë§·)
7. [ì¼ë³¸ì–´ ìŒì„± ì¸ì‹ íŒ](#7-ì¼ë³¸ì–´-ìŒì„±-ì¸ì‹-íŒ)
8. [ì»¤ë®¤ë‹ˆí‹° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤](#8-ì»¤ë®¤ë‹ˆí‹°-ë² ìŠ¤íŠ¸-í”„ë™í‹°ìŠ¤)
9. [ê¶Œì¥ ì„¤ì • ë° ì›Œí¬í”Œë¡œìš°](#9-ê¶Œì¥-ì„¤ì •-ë°-ì›Œí¬í”Œë¡œìš°)

---

## 1. stable-ts (stable-whisper)

### ğŸ“Œ ê°œìš”
OpenAI Whisperë¥¼ ìˆ˜ì •í•˜ì—¬ **ë” ì•ˆì •ì ì¸ íƒ€ì„ìŠ¤íƒ¬í”„**ë¥¼ ìƒì„±í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬. ê°€ì‚¬ ì‹±í¬ì˜ í•µì‹¬ ë„êµ¬.

### ğŸ”„ ìµœì‹  ë²„ì „ (2025ë…„ 12ì›” ê¸°ì¤€)
| ë²„ì „ | ì¶œì‹œì¼ | ì£¼ìš” ë³€ê²½ì‚¬í•­ |
|------|--------|--------------|
| **2.19.1** | 2025.08 | ìµœì‹  ì•ˆì • ë²„ì „ |
| 2.19.0 | 2025.03 | ì£¼ìš” ì—…ë°ì´íŠ¸ |
| 2.18.3 | 2025.01 | ë²„ê·¸ ìˆ˜ì • |
| 2.18.0 | 2024.12 | ê¸°ëŠ¥ ê°œì„  |

### âš™ï¸ í•µì‹¬ ê¸°ëŠ¥

#### 1) Forced Alignment (ê°•ì œ ì •ë ¬) - ê°€ì‚¬ ì‹±í¬ì˜ í•µì‹¬!
```python
import stable_whisper

model = stable_whisper.load_model('large-v3', device='cuda')

# í…ìŠ¤íŠ¸ì™€ ì˜¤ë””ì˜¤ ì •ë ¬ (ê°€ì‚¬ ì‹±í¬)
result = model.align(
    'audio.mp3', 
    lyrics_text,  # ì›ë³¸ ê°€ì‚¬ í…ìŠ¤íŠ¸
    language='ja'  # ì¼ë³¸ì–´
)
```

#### 2) ê³ ê¸‰ ì „ì²˜ë¦¬ ì˜µì…˜
```python
result = model.transcribe(
    'audio.mp3',
    language='ja',
    
    # ğŸ”‡ ì¹¨ë¬µ ì–µì œ (VAD)
    suppress_silence=True,
    vad=True,  # Silero VAD ì‚¬ìš©
    vad_threshold=0.35,  # ìŒì„± ê°ì§€ ì„ê³„ê°’ (0.35 ê¶Œì¥)
    
    # ğŸµ ë…¸ì´ì¦ˆ ì œê±°
    denoiser='demucs',  # Demucsë¡œ ë³´ì»¬ ë¶„ë¦¬
    only_voice_freq=True,  # 200-5000Hzë§Œ ì‚¬ìš© (ìŒì„± ì£¼íŒŒìˆ˜)
    
    # ğŸ“Š ì„¸ê·¸ë¨¼íŠ¸ ì¬ê·¸ë£¹í™”
    regroup=True,  # ìì—°ìŠ¤ëŸ¬ìš´ ê²½ê³„ë¡œ ì¬ê·¸ë£¹í™”
    
    # ğŸ”„ ê¸°íƒ€ ì˜µì…˜
    mel_first=True,  # ê¸´ ì˜¤ë””ì˜¤ì‹œ ë©”ëª¨ë¦¬ ì ˆì•½
    word_timestamps=True,  # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„
)
```

#### 3) ì¶œë ¥ í¬ë§·
```python
# SRT/VTT ì¶œë ¥
result.to_srt_vtt('output.srt', word_level=False)  # ë¼ì¸ë³„
result.to_srt_vtt('output_word.srt', word_level=True)  # ë‹¨ì–´ë³„

# ASS ì¶œë ¥ (ì¹´ë¼ì˜¤ì¼€ ìŠ¤íƒ€ì¼)
result.to_ass('output.ass')

# JSON ì €ì¥ (ì¬ì²˜ë¦¬ìš©)
result.save_as_json('output.json')
```

#### 4) ì„¸ê·¸ë¨¼íŠ¸ ì¡°ì‘ ë©”ì„œë“œ
```python
# êµ¬ë‘ì ìœ¼ë¡œ ë¶„í• 
result.split_by_punctuation([('.', ' '), 'ã€‚', '?', 'ï¼Ÿ', ',', 'ï¼Œ'])

# ì¹¨ë¬µ êµ¬ê°„ìœ¼ë¡œ ë¶„í• 
result.split_by_gap(0.5)  # 0.5ì´ˆ ì´ìƒ gapì—ì„œ ë¶„í• 

# ì§§ì€ ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•©
result.merge_by_gap(0.15, max_words=3)
```

### ğŸ“¦ ì„¤ì¹˜
```bash
pip install stable-ts

# ë˜ëŠ” ìµœì‹  ê°œë°œ ë²„ì „
pip install git+https://github.com/jianfch/stable-ts.git
```

### âš ï¸ ì£¼ì˜ì‚¬í•­
- `word_timestamps=False` ì‚¬ìš© ê¸ˆì§€ - ì„¸ê·¸ë¨¼íŠ¸ íƒ€ì„ìŠ¤íƒ¬í”„ ë³´ì •ì— í•„ìš”
- ê¸´ ì˜¤ë””ì˜¤ì—ì„œ ì´ìƒ ë™ì‘ ì‹œ `mel_first=True` ì‚¬ìš©

---

## 2. Whisper ëª¨ë¸ ê³„ì—´

### ğŸ† ëª¨ë¸ ë¹„êµ (2025ë…„ 12ì›” ê¸°ì¤€)

| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | VRAM | ì†ë„ | ì •í™•ë„ | ë¹„ê³  |
|------|----------|------|------|--------|------|
| **large-v3** | 1.55B | ~10GB | ê¸°ì¤€ | ìµœê³  | ğŸ† ìµœê³  í’ˆì§ˆ |
| **large-v3-turbo** | 809M | ~6GB | 6ë°°â†‘ | large-v2ê¸‰ | âš¡ ì†ë„/í’ˆì§ˆ ê· í˜• |
| distil-large-v3 | 756M | ~4GB | 6ë°°â†‘ | v3ì˜ 99% | ì˜ì–´ ì „ìš© |
| medium | 769M | ~5GB | ë¹ ë¦„ | ì¢‹ìŒ | ë‹¤êµ­ì–´ ì§€ì› |
| small | 244M | ~2GB | ë§¤ìš° ë¹ ë¦„ | ë³´í†µ | ì €ì‚¬ì–‘ìš© |

### ğŸ†• large-v3-turbo (2024ë…„ 10ì›” ì¶œì‹œ)

**í•µì‹¬ íŠ¹ì§•:**
- ë””ì½”ë” ë ˆì´ì–´ 32ê°œ â†’ 4ê°œë¡œ ì¶•ì†Œ (Distil-Whisper ì˜ê°)
- large-v3 ëŒ€ë¹„ **6ë°° ë¹ ë¥¸ ì¶”ë¡  ì†ë„**
- large-v2ì™€ ë™ë“±í•œ ì •í™•ë„ ìœ ì§€
- ë²ˆì—­ ì„±ëŠ¥ì€ í•˜ë½ (transcription ë°ì´í„°ë¡œë§Œ fine-tune)

**ì¼ë³¸ì–´ ì„±ëŠ¥:**
- large-v2ì™€ ë™ë“±í•œ ì¼ë³¸ì–´ ì •í™•ë„ ìœ ì§€
- íƒœêµ­ì–´, ê´‘ë‘¥ì–´ ë“± ì¼ë¶€ ì–¸ì–´ì—ì„œë§Œ ì •í™•ë„ í•˜ë½

```python
# large-v3-turbo ì‚¬ìš©
model = stable_whisper.load_model('large-v3-turbo', device='cuda')
```

### ğŸ“Š WER (Word Error Rate) ë²¤ì¹˜ë§ˆí¬
| ëª¨ë¸ | ì „ì²´ WER | ì¼ë³¸ì–´ WER |
|------|----------|-----------|
| large-v3 | 7.88% | ~5-6% |
| large-v3-turbo | 7.75% | large-v2ê¸‰ |
| large-v2 | ~8% | ~6% |

---

## 3. faster-whisper

### ğŸ“Œ ê°œìš”
CTranslate2 ê¸°ë°˜ Whisper ì¬êµ¬í˜„. **ì›ë³¸ ëŒ€ë¹„ 4ë°° ë¹ ë¥´ê³  ë©”ëª¨ë¦¬ íš¨ìœ¨ì **.

### ğŸ”„ ìµœì‹  ë²„ì „
| ë²„ì „ | ì¶œì‹œì¼ | ë¹„ê³  |
|------|--------|------|
| **1.2.1** | 2025.10 | ìµœì‹  |
| 1.2.0 | 2025.08 | |
| 1.1.1 | 2025.01 | |
| 1.1.0 | 2024.11 | turbo ì§€ì› |

### âš¡ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (13ë¶„ ì˜¤ë””ì˜¤, RTX 3070 Ti)

| êµ¬í˜„ì²´ | ì •ë°€ë„ | ì‹œê°„ | GPU ë©”ëª¨ë¦¬ | CPU ë©”ëª¨ë¦¬ |
|--------|--------|------|-----------|-----------|
| faster-whisper large-v3 | fp16 | 52ì´ˆ | 4521MB | 901MB |
| faster-whisper large-v3 | int8 | 53ì´ˆ | 2953MB | 2261MB |
| faster-large-v3-turbo | fp16 | **19ì´ˆ** | - | - |
| faster-distil-large-v3 | fp16 | 26ì´ˆ | 2409MB | 900MB |

### ğŸ’» ì‚¬ìš©ë²•
```python
from faster_whisper import WhisperModel

# ëª¨ë¸ ë¡œë“œ
model = WhisperModel(
    "large-v3",
    device="cuda",
    compute_type="float16"  # ë˜ëŠ” "int8" (ë©”ëª¨ë¦¬ ì ˆì•½)
)

# ì „ì‚¬
segments, info = model.transcribe(
    "audio.mp3",
    language="ja",
    beam_size=5,
    vad_filter=True,  # VAD í•„í„° í™œì„±í™”
    vad_parameters=dict(
        min_silence_duration_ms=500,
        speech_pad_ms=400
    )
)

for segment in segments:
    print(f"[{segment.start:.2f}s -> {segment.end:.2f}s] {segment.text}")
```

### ğŸ”§ ì–‘ìí™” ì˜µì…˜
| compute_type | ë©”ëª¨ë¦¬ | ì†ë„ | ì •í™•ë„ | ê¶Œì¥ í™˜ê²½ |
|--------------|--------|------|--------|----------|
| float32 | ë†’ìŒ | ëŠë¦¼ | ìµœê³  | CPU |
| float16 | ì¤‘ê°„ | ë¹ ë¦„ | ë†’ìŒ | GPU (ê¶Œì¥) |
| int8 | ë‚®ìŒ | ë¹ ë¦„ | ì¢‹ìŒ | ì €ì‚¬ì–‘ GPU |
| int8_float16 | ë‚®ìŒ | ë¹ ë¦„ | ì¢‹ìŒ | GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ |

### ğŸ“¦ ì„¤ì¹˜
```bash
pip install faster-whisper

# CUDA 12 í•„ìš” (ìµœì‹  ë²„ì „)
# cuDNN 9 í•„ìš”
```

---

## 4. PyTorch & CUDA

### ğŸ”„ ìµœì‹  ë²„ì „ (2025ë…„ 12ì›”)

| PyTorch | CUDA ì§€ì› | ì¶œì‹œì¼ |
|---------|-----------|--------|
| **2.9.0** | 12.6, 12.8, 13.0 | ìµœì‹  |
| 2.8.0 | 12.6, 12.8, 12.9 | |
| 2.7.1 | 12.4, 12.6 | |
| 2.5.1 | 11.8, 12.1, 12.4 | ì•ˆì • |

### ğŸ’» RTX 3070 Ti ê¶Œì¥ ì„¤ì •

```bash
# CUDA 12.4 + PyTorch 2.5.1 (ì•ˆì •ì ì¸ ì¡°í•©)
pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 \
    --index-url https://download.pytorch.org/whl/cu124

# ë˜ëŠ” ìµœì‹  ë²„ì „
pip install torch torchvision torchaudio \
    --index-url https://download.pytorch.org/whl/cu126
```

### âœ… GPU í™•ì¸
```python
import torch

print(f"PyTorch ë²„ì „: {torch.__version__}")
print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
print(f"CUDA ë²„ì „: {torch.version.cuda}")
print(f"GPU ì´ë¦„: {torch.cuda.get_device_name(0)}")
print(f"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
```

### âš ï¸ ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

| ë¬¸ì œ | í•´ê²°ì±… |
|------|--------|
| `torch.cuda.is_available()` = False | PyTorch CUDA ë²„ì „ê³¼ ì‹œìŠ¤í…œ CUDA ë²„ì „ í™•ì¸ |
| CUDA out of memory | `compute_type="int8"` ë˜ëŠ” ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš© |
| ë“œë¼ì´ë²„ í˜¸í™˜ì„± | `nvidia-smi`ë¡œ ë“œë¼ì´ë²„ ë²„ì „ í™•ì¸ í›„ ì—…ë°ì´íŠ¸ |

### ğŸ”§ CUDA ë²„ì „ í˜¸í™˜ì„±
- **RTX 3070 Ti**: CUDA 11.0 ì´ìƒ í•„ìš”
- **RTX 40xx ì‹œë¦¬ì¦ˆ**: CUDA 11.8 ì´ìƒ ê¶Œì¥
- **RTX 50xx ì‹œë¦¬ì¦ˆ**: CUDA 12.8 ì´ìƒ í•„ìš” (Blackwell)

---

## 5. Demucs (ë³´ì»¬ ë¶„ë¦¬)

### ğŸ“Œ ê°œìš”
Meta/Kyutaiì˜ **ìµœì²¨ë‹¨ ìŒì› ë¶„ë¦¬ ëª¨ë¸**. ë…¸ë˜ì—ì„œ ë³´ì»¬ì„ ë¶„ë¦¬í•˜ì—¬ ê°€ì‚¬ ì¸ì‹ ì •í™•ë„ í–¥ìƒ.

### ğŸ—ï¸ ì•„í‚¤í…ì²˜ (v4 - Hybrid Transformer Demucs)

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      Cross-Domain Transformer    â”‚
                    â”‚   (Self-Attention + Cross-Attn)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Time Domain    â”‚                               â”‚  Frequency Domain â”‚
â”‚    U-Net        â”‚                               â”‚      U-Net        â”‚
â”‚ (Waveform)      â”‚                               â”‚  (Spectrogram)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ¯ ì‚¬ì „ í•™ìŠµ ëª¨ë¸

| ëª¨ë¸ | ì„¤ëª… | í’ˆì§ˆ | ì†ë„ |
|------|------|------|------|
| **htdemucs_ft** | Fine-tuned HT Demucs | ìµœê³  ğŸ† | 4ë°° ëŠë¦¼ |
| **htdemucs** | ê¸°ë³¸ HT Demucs | ë§¤ìš° ì¢‹ìŒ | ë¹ ë¦„ |
| htdemucs_6s | 6ì†ŒìŠ¤ (í”¼ì•„ë…¸, ê¸°íƒ€ ì¶”ê°€) | ì‹¤í—˜ì  | ë³´í†µ |
| hdemucs_mmi | Hybrid Demucs v3 | ì¢‹ìŒ | ë¹ ë¦„ |

### ğŸ“Š ë²¤ì¹˜ë§ˆí¬ (MUSDB HQ)

| ëª¨ë¸ | SDR (dB) | ì„¤ëª… |
|------|----------|------|
| HT Demucs f.t. | **9.20** | ìµœê³  ì„±ëŠ¥ |
| HT Demucs | 9.00 | ê¸°ë³¸ |
| Hybrid Demucs v3 | 8.5+ | ì´ì „ ë²„ì „ |

*SDR: Signal-to-Distortion Ratio, ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ*

### ğŸ’» ì‚¬ìš©ë²•

```python
import demucs.separate

# CLI ì‚¬ìš©
# demucs -n htdemucs_ft --two-stems=vocals audio.mp3

# Pythonì—ì„œ ì‚¬ìš©
from demucs import pretrained
from demucs.apply import apply_model
import torch
import torchaudio

# ëª¨ë¸ ë¡œë“œ
model = pretrained.get_model('htdemucs_ft')
model.cuda()
model.eval()

# ì˜¤ë””ì˜¤ ë¡œë“œ
wav, sr = torchaudio.load('audio.mp3')
wav = wav.cuda()

# ë¶„ë¦¬ ì‹¤í–‰
with torch.no_grad():
    sources = apply_model(model, wav[None], device='cuda')[0]

# sources: [drums, bass, other, vocals]
vocals = sources[3]  # ë³´ì»¬ ì¶”ì¶œ
```

### ğŸ”§ stable-tsì™€ í†µí•©
```python
result = model.transcribe(
    'audio.mp3',
    denoiser='demucs',  # Demucsë¡œ ë³´ì»¬ ë¶„ë¦¬ í›„ ì²˜ë¦¬
    language='ja'
)
```

### ğŸ“¦ ì„¤ì¹˜
```bash
pip install demucs

# ë˜ëŠ”
pip install -U demucs
```

### âš ï¸ ì°¸ê³ ì‚¬í•­
- ì €ì(Alexandre DÃ©fossez)ê°€ Meta í‡´ì‚¬ í›„ Kyutaië¡œ ì´ë™
- ê³µì‹ ì €ì¥ì†Œ: `github.com/adefossez/demucs` (ìƒˆ ìœ„ì¹˜)
- ì ê·¹ì ì¸ ê°œë°œì€ ì¤‘ë‹¨ë˜ì—ˆìœ¼ë‚˜ ë²„ê·¸ ìˆ˜ì •ì€ ì§„í–‰

---

## 6. LRC íŒŒì¼ í¬ë§·

### ğŸ“ ê¸°ë³¸ LRC (Simple LRC)
```lrc
[ar:ì•„í‹°ìŠ¤íŠ¸ëª…]
[ti:ê³¡ ì œëª©]
[al:ì•¨ë²”ëª…]
[length:3:45]

[00:12.00]ì²« ë²ˆì§¸ ê°€ì‚¬ ë¼ì¸
[00:17.20]ë‘ ë²ˆì§¸ ê°€ì‚¬ ë¼ì¸
[00:21.10]ì„¸ ë²ˆì§¸ ê°€ì‚¬ ë¼ì¸
```

**íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹:** `[mm:ss.xx]` (ë¶„:ì´ˆ.ë°€ë¦¬ì´ˆ)

### ğŸŒŸ Enhanced LRC (ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„)

ì¹´ë¼ì˜¤ì¼€ ìŠ¤íƒ€ì¼ë¡œ **ë‹¨ì–´ ë‹¨ìœ„** í•˜ì´ë¼ì´íŠ¸ ê°€ëŠ¥:

```lrc
[ar:Artist Name]
[ti:Song Title]
[la:ja]
[re:stable-ts]

[00:12.34]<00:12.34>è¡Œã“ã† <00:12.89>ã“ã® <00:13.45>å£°ã« <00:13.78>å°ã‹ã‚Œ
[00:18.50]<00:18.50>ä»Šæ—¥ã‚‚ <00:18.95>ã¾ãŸ <00:19.40>ä¸€æ­© <00:19.85>ãšã¤
```

**Enhanced í˜•ì‹:**
- ë¼ì¸ ì‹œì‘: `[mm:ss.xx]`
- ë‹¨ì–´ ì‹œì‘: `<mm:ss.xx>`

### ğŸ”„ stable-tsì—ì„œ LRC ì¶œë ¥

```python
# ë¼ì¸ë³„ LRC
result.to_srt_vtt('output.lrc', word_level=False)

# ë‹¨ì–´ë³„ LRC (Enhanced)
result.to_srt_vtt('output_word.lrc', word_level=True)
```

### ğŸ“Š ì¶œë ¥ í¬ë§· ë¹„êµ

| í¬ë§· | ìš©ë„ | ë‹¨ì–´ íƒ€ì„ìŠ¤íƒ¬í”„ | í˜¸í™˜ì„± |
|------|------|----------------|--------|
| LRC (Simple) | ì¼ë°˜ í”Œë ˆì´ì–´ | âŒ | ë†’ìŒ |
| LRC (Enhanced) | ì¹´ë¼ì˜¤ì¼€ | âœ… | ì¤‘ê°„ |
| SRT | ìë§‰ | âŒ | ë†’ìŒ |
| VTT | ì›¹ ìë§‰ | âœ… | ë†’ìŒ |
| ASS | ê³ ê¸‰ ìë§‰/ì¹´ë¼ì˜¤ì¼€ | âœ… | ì¤‘ê°„ |

---

## 7. ì¼ë³¸ì–´ ìŒì„± ì¸ì‹ íŒ

### ğŸ¯ ìµœì  ì„¤ì •

```python
result = model.transcribe(
    'audio.mp3',
    language='ja',  # í•„ìˆ˜: ì¼ë³¸ì–´ ëª…ì‹œ
    
    # ì¼ë³¸ì–´ ìµœì í™” ì˜µì…˜
    initial_prompt="ä»¥ä¸‹ã¯æ—¥æœ¬èªã®æ­Œè©ã§ã™ã€‚",  # ì¼ë³¸ì–´ ê°€ì‚¬ì„ì„ ëª…ì‹œ
    
    # VAD ì‚¬ìš© (ë°°ê²½ ìŒì•… êµ¬ê°„ ì œê±°)
    vad=True,
    vad_threshold=0.35,
    
    # ì„¸ê·¸ë¨¼íŠ¸ ì¡°ì •
    regroup=True,
)
```

### âš ï¸ ì¼ë°˜ì ì¸ ë¬¸ì œì™€ í•´ê²°ì±…

| ë¬¸ì œ | ì›ì¸ | í•´ê²°ì±… |
|------|------|--------|
| ê°€ì‚¬ ëˆ„ë½ | ë°°ê²½ ìŒì•…ì´ ë³´ì»¬ ë®ìŒ | Demucsë¡œ ë³´ì»¬ ë¶„ë¦¬ |
| í™˜ê°(Hallucination) | ì¹¨ë¬µ êµ¬ê°„ì—ì„œ ë°œìƒ | VAD í•„í„° ì‚¬ìš© |
| íƒ€ì„ìŠ¤íƒ¬í”„ ì˜¤ì°¨ | 30ì´ˆ ì²­í¬ ê²½ê³„ ë¬¸ì œ | VAD + ì„¸ê·¸ë¨¼íŠ¸ ì¬ê·¸ë£¹í™” |
| ë°˜ë³µë˜ëŠ” í…ìŠ¤íŠ¸ | ëª¨ë¸ í™˜ê° | `suppress_ts_tokens=True` |

### ğŸ¤ ë³´ì»¬ ë¶„ë¦¬ ê¶Œì¥

ë…¸ë˜ ê°€ì‚¬ ì¸ì‹ ì‹œ **Demucs ë³´ì»¬ ë¶„ë¦¬ í•„ìˆ˜**:

```python
# ë°©ë²• 1: stable-ts ë‚´ì¥
result = model.transcribe('audio.mp3', denoiser='demucs', language='ja')

# ë°©ë²• 2: ë³„ë„ ì „ì²˜ë¦¬
# 1. Demucsë¡œ vocals.wav ì¶”ì¶œ
# 2. vocals.wavë¥¼ stable-tsì— ì…ë ¥
```

### ğŸ“Š ì¼ë³¸ì–´ WER (Word Error Rate)

Whisper large-v3 ê¸°ì¤€:
- ê¹¨ë—í•œ ìŒì„±: **~5%**
- ë…¸ë˜ (ë³´ì»¬ ë¶„ë¦¬ í›„): **~10-15%**
- ë…¸ë˜ (ì›ë³¸): **~25-35%**

---

## 8. ì»¤ë®¤ë‹ˆí‹° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### ğŸ”¥ ê°€ì‚¬ ì‹±í¬ íŒŒì´í”„ë¼ì¸ (ê¶Œì¥)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì›ë³¸ MP3   â”‚ -> â”‚ Demucs       â”‚ -> â”‚ stable-ts     â”‚ -> â”‚ LRC ì¶œë ¥ â”‚
â”‚             â”‚    â”‚ (ë³´ì»¬ ë¶„ë¦¬)  â”‚    â”‚ (align/ê°•ì œì •ë ¬)â”‚    â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ vocals.wav   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ’¡ ì»¤ë®¤ë‹ˆí‹° íŒ ëª¨ìŒ

#### 1) í™˜ê°(Hallucination) ì¤„ì´ê¸°
```python
result = model.transcribe(
    audio,
    temperature=0,  # ê²°ì •ë¡ ì  ì¶œë ¥
    suppress_silence=True,
    vad=True,
    condition_on_previous_text=False,  # ì´ì „ í…ìŠ¤íŠ¸ ì˜ì¡´ ì œê±°
)
```

#### 2) íƒ€ì„ìŠ¤íƒ¬í”„ ì •í™•ë„ í–¥ìƒ
```python
# Silero VAD ì‚¬ìš©
result = model.transcribe(
    audio,
    vad='silero-vad',
    vad_threshold=0.35,
    min_word_dur=0.1,  # ìµœì†Œ ë‹¨ì–´ ê¸¸ì´
)
```

#### 3) ê¸´ ì˜¤ë””ì˜¤ ì²˜ë¦¬
```python
# ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬
result = model.transcribe(
    audio,
    mel_first=True,  # ì „ì²´ ì˜¤ë””ì˜¤ë¥¼ ë¨¼ì € Mel ìŠ¤í™íŠ¸ë¡œê·¸ë¨ìœ¼ë¡œ ë³€í™˜
)
```

#### 4) ì¼ë³¸ì–´ + ì˜ì–´ í˜¼í•© ê°€ì‚¬
```python
# ì–¸ì–´ ìë™ ê°ì§€ ì‚¬ìš©
result = model.transcribe(
    audio,
    language=None,  # ìë™ ê°ì§€
    # ë˜ëŠ”
    language='ja',  # ì£¼ ì–¸ì–´ ì„¤ì • (ì˜ì–´ ë‹¨ì–´ë„ ì¸ì‹ë¨)
)
```

### ğŸ› ï¸ ìœ ìš©í•œ ë„êµ¬ë“¤

| ë„êµ¬ | ìš©ë„ | ë§í¬ |
|------|------|------|
| **WhisperX** | ì •ë°€ íƒ€ì„ìŠ¤íƒ¬í”„ + í™”ì ë¶„ë¦¬ | github.com/m-bain/whisperX |
| **lyrics-transcriber** | ì¹´ë¼ì˜¤ì¼€ LRC/ASS ìƒì„± | pypi.org/project/lyrics-transcriber |
| **Open-Lyrics** | faster-whisper + GPT ë²ˆì—­ | - |
| **whisper-diarize** | í™”ì ë¶„ë¦¬ | - |

---

## 9. ê¶Œì¥ ì„¤ì • ë° ì›Œí¬í”Œë¡œìš°

### ğŸ¯ í˜¸ì‹œë§ˆì¹˜ ìŠ¤ì´ì„¸ì´ í”„ë¡œì íŠ¸ ìµœì  ì„¤ì •

```python
import stable_whisper
import torch

# GPU í™•ì¸
assert torch.cuda.is_available(), "CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!"
print(f"GPU: {torch.cuda.get_device_name(0)}")
print(f"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")

# ëª¨ë¸ ë¡œë“œ (RTX 3070 Ti 8GBì— ìµœì )
model = stable_whisper.load_model(
    'large-v3',  # ë˜ëŠ” 'large-v3-turbo' (ë” ë¹ ë¦„)
    device='cuda'
)

# ê°€ì‚¬ ì½ê¸°
with open('lyrics/stellar_stellar.txt', 'r', encoding='utf-8') as f:
    lyrics = f.read().strip()

# ê°•ì œ ì •ë ¬ (ê°€ì‚¬ ì‹±í¬)
result = model.align(
    'songs/stellar_stellar.mp3',
    lyrics,
    language='ja',
    
    # ì„ íƒì : ë³´ì»¬ ë¶„ë¦¬
    # denoiser='demucs',
)

# ì¶œë ¥
result.to_srt_vtt('output/stellar_stellar.lrc', word_level=False)
```

### ğŸ“Š RTX 3070 Ti ì˜ˆìƒ ì„±ëŠ¥

| ì‘ì—… | ëª¨ë¸ | 3ë¶„ ê³¡ ì²˜ë¦¬ ì‹œê°„ | VRAM ì‚¬ìš© |
|------|------|-----------------|-----------|
| align (ê°€ì‚¬ ì •ë ¬) | large-v3 | ~10-15ì´ˆ | ~4-5GB |
| transcribe | large-v3 | ~20-30ì´ˆ | ~5-6GB |
| align + demucs | large-v3 | ~30-45ì´ˆ | ~6-7GB |

### ğŸ“¦ í™˜ê²½ ì„¤ì • ìš”ì•½

```bash
# 1. ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv suisei_lyrics
source suisei_lyrics/bin/activate  # Linux/Mac
# suisei_lyrics\Scripts\activate  # Windows

# 2. PyTorch CUDA ì„¤ì¹˜
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# 3. í•µì‹¬ íŒ¨í‚¤ì§€
pip install stable-ts
pip install demucs

# 4. (ì„ íƒ) faster-whisper
pip install faster-whisper

# 5. í™•ì¸
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
python -c "import stable_whisper; print('stable-ts OK')"
```

### ğŸ—‚ï¸ ê¶Œì¥ í´ë” êµ¬ì¡°

```
suisei_lyrics/
â”œâ”€â”€ songs/                    # MP3 íŒŒì¼
â”‚   â”œâ”€â”€ stellar_stellar.mp3
â”‚   â”œâ”€â”€ template.mp3
â”‚   â””â”€â”€ ghost.mp3
â”œâ”€â”€ lyrics/                   # ì›ë³¸ ê°€ì‚¬ (UTF-8)
â”‚   â”œâ”€â”€ stellar_stellar.txt
â”‚   â”œâ”€â”€ template.txt
â”‚   â””â”€â”€ ghost.txt
â”œâ”€â”€ vocals/                   # (ì„ íƒ) Demucs ë³´ì»¬ ë¶„ë¦¬ ê²°ê³¼
â”‚   â””â”€â”€ stellar_stellar_vocals.wav
â”œâ”€â”€ output/                   # ê²°ê³¼ LRC íŒŒì¼
â”‚   â”œâ”€â”€ stellar_stellar.lrc
â”‚   â””â”€â”€ stellar_stellar_word.lrc
â”œâ”€â”€ sync_suisei.py           # ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ requirements.txt
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [stable-ts GitHub](https://github.com/jianfch/stable-ts)
- [faster-whisper GitHub](https://github.com/SYSTRAN/faster-whisper)
- [Demucs GitHub](https://github.com/adefossez/demucs)
- [PyTorch ì„¤ì¹˜](https://pytorch.org/get-started/locally/)

### ë…¼ë¬¸
- [Hybrid Transformers for Music Source Separation](https://arxiv.org/abs/2211.08553)
- [Robust Speech Recognition via Large-Scale Weak Supervision](https://arxiv.org/abs/2212.04356) (Whisper)

### ì»¤ë®¤ë‹ˆí‹°
- [Whisper Discussions](https://github.com/openai/whisper/discussions)
- [stable-ts Issues](https://github.com/jianfch/stable-ts/issues)

---

## 10. ì¶”ê°€ ë„êµ¬: WhisperX

### ğŸ“Œ ê°œìš”
WhisperXëŠ” Whisperì— **VAD + Forced Alignment + í™”ì ë¶„ë¦¬(Diarization)**ë¥¼ ì¶”ê°€í•œ í™•ì¥ ë„êµ¬ì…ë‹ˆë‹¤.

### ğŸ”§ ì•„í‚¤í…ì²˜
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Audio  â”‚ -> â”‚ Silero    â”‚ -> â”‚ Whisper      â”‚ -> â”‚ Wav2Vec2       â”‚
â”‚         â”‚    â”‚ VAD       â”‚    â”‚ (faster-     â”‚    â”‚ Forced         â”‚
â”‚         â”‚    â”‚           â”‚    â”‚  whisper)    â”‚    â”‚ Alignment      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“                  â†“                    â†“
              ìŒì„± êµ¬ê°„ ê°ì§€      í…ìŠ¤íŠ¸ ì „ì‚¬          ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„
```

### ğŸ’» ì‚¬ìš©ë²•
```python
import whisperx

device = "cuda"
audio_file = "audio.mp3"

# 1. ì „ì‚¬ (faster-whisper ë°±ì—”ë“œ)
model = whisperx.load_model("large-v3", device, compute_type="float16")
result = model.transcribe(audio_file, batch_size=16)

# 2. ì •ë ¬ ëª¨ë¸ ë¡œë“œ
model_a, metadata = whisperx.load_align_model(
    language_code=result["language"], 
    device=device
)

# 3. ê°•ì œ ì •ë ¬ (ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„)
result_aligned = whisperx.align(
    result["segments"], 
    model_a, 
    metadata, 
    audio_file, 
    device
)

print(result_aligned["word_segments"])  # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„
```

### ğŸ“Š stable-ts vs WhisperX

| ê¸°ëŠ¥ | stable-ts | WhisperX |
|------|-----------|----------|
| íƒ€ì„ìŠ¤íƒ¬í”„ ì•ˆì •í™” | âœ… | âœ… |
| ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ | âœ… | âœ… |
| ê°•ì œ ì •ë ¬ (ê°€ì‚¬ ì‹±í¬) | âœ… `model.align()` | âŒ (ì „ì‚¬ í›„ ì •ë ¬ë§Œ) |
| í™”ì ë¶„ë¦¬ | âŒ | âœ… |
| ë°°ì¹˜ ì²˜ë¦¬ | âŒ | âœ… (70x ì‹¤ì‹œê°„) |
| ë°±ì—”ë“œ | OpenAI Whisper | faster-whisper |

**ê°€ì‚¬ ì‹±í¬ í”„ë¡œì íŠ¸**: stable-ts ê¶Œì¥ (`model.align()` ê¸°ëŠ¥ ë•Œë¬¸)

### ğŸ“¦ ì„¤ì¹˜
```bash
pip install whisperx
# ë˜ëŠ”
pip install git+https://github.com/m-bain/whisperX.git
```

---

## 11. Silero VAD ìƒì„¸

### ğŸ“Œ ê°œìš”
**Silero VAD**ëŠ” ìŒì„± í™œë™ ê°ì§€(Voice Activity Detection) ëª¨ë¸ë¡œ, Whisper ì „ì²˜ë¦¬ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤.

### ğŸ¯ í•µì‹¬ íŠ¹ì§•
- **ì´ˆê²½ëŸ‰**: ~1.8MB ëª¨ë¸ í¬ê¸°
- **ì´ˆê³ ì†**: 30ms ì²­í¬ë‹¹ <1ms ì²˜ë¦¬
- **ë‹¤êµ­ì–´**: 100ê°œ+ ì–¸ì–´ ì§€ì›
- **ìƒ˜í”Œë ˆì´íŠ¸**: 8kHz, 16kHz ì§€ì›

### âš™ï¸ stable-tsì—ì„œ VAD ì„¤ì •

```python
result = model.transcribe(
    'audio.mp3',
    language='ja',
    
    # VAD í™œì„±í™”
    vad=True,  # ë˜ëŠ” 'silero-vad'
    
    # VAD íŒŒë¼ë¯¸í„°
    vad_threshold=0.35,      # ìŒì„± ê°ì§€ ì„ê³„ê°’ (0.0-1.0)
                              # ë†’ì„ìˆ˜ë¡ ë³´ìˆ˜ì  (ë…¸ì´ì¦ˆ ë¬´ì‹œ)
                              # ë‚®ì„ìˆ˜ë¡ ë¯¼ê° (ë¶€ë“œëŸ¬ìš´ ìŒì„±ë„ ê°ì§€)
    
    min_silence_duration_ms=500,  # ìµœì†Œ ì¹¨ë¬µ ê¸¸ì´ (ms)
    speech_pad_ms=400,            # ìŒì„± ì „í›„ íŒ¨ë”© (ms)
)
```

### ğŸ“Š VAD ì„ê³„ê°’ ê°€ì´ë“œ

| í™˜ê²½ | ê¶Œì¥ ì„ê³„ê°’ | ì„¤ëª… |
|------|------------|------|
| ê¹¨ë—í•œ ìŒì„± | 0.5 | ê¸°ë³¸ê°’ |
| ë…¸ì´ì¦ˆ ìˆëŠ” í™˜ê²½ | 0.6-0.7 | ë” ë³´ìˆ˜ì  |
| ë¶€ë“œëŸ¬ìš´ ìŒì„± | 0.3-0.4 | ë” ë¯¼ê° |
| **ë…¸ë˜/ìŒì•…** | **0.35** | ê¶Œì¥ |

### âš ï¸ ì£¼ì˜ì‚¬í•­
- Silero VAD v4ì—ì„œ ê¸´ ì¹¨ë¬µ êµ¬ê°„ì— í™˜ê°ì´ ë°œìƒí•  ìˆ˜ ìˆìŒ
- ì¼ë¶€ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ v3.1 ê¶Œì¥í•˜ëŠ” ê²½ìš°ë„ ìˆìŒ

---

## 12. í™˜ê°(Hallucination) ë¬¸ì œ í•´ê²°

### ğŸ” í™˜ê°ì´ë€?
Whisperê°€ ì‹¤ì œ ìŒì„±ì— ì—†ëŠ” í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” í˜„ìƒ:
- "Thanks for watching"
- "Subscribe to my channel"
- ê°™ì€ ë¬¸ì¥ ë¬´í•œ ë°˜ë³µ (Looping)

### ğŸ›¡ï¸ í™˜ê° ë°©ì§€ ì „ëµ

#### 1) VAD ì „ì²˜ë¦¬ (í•„ìˆ˜)
```python
result = model.transcribe(
    audio,
    vad=True,
    vad_threshold=0.35,
    suppress_silence=True,
)
```

#### 2) condition_on_previous_text ë¹„í™œì„±í™”
```python
result = model.transcribe(
    audio,
    condition_on_previous_text=False,  # ì´ì „ í…ìŠ¤íŠ¸ ì˜ì¡´ ì œê±°
)
```

#### 3) ì˜¨ë„ ì„¤ì •
```python
result = model.transcribe(
    audio,
    temperature=0,  # ê²°ì •ë¡ ì  ì¶œë ¥ (í™˜ê° ê°ì†Œ)
)
```

#### 4) ë³´ì»¬ ë¶„ë¦¬ (ë…¸ë˜ì˜ ê²½ìš°)
```python
result = model.transcribe(
    audio,
    denoiser='demucs',  # ë°°ê²½ ìŒì•… ì œê±°
)
```

#### 5) FFmpeg ì¹¨ë¬µ ì œê±° ì „ì²˜ë¦¬
```bash
ffmpeg -y -i input.mp3 \
    -af "silenceremove=start_periods=1:stop_periods=-1:start_threshold=-50dB:stop_threshold=-50dB:start_silence=0.1:stop_silence=0.1" \
    output.mp3
```

#### 6) ì••ì¶•ë¥  ì²´í¬ (í›„ì²˜ë¦¬)
```python
# í™˜ê° ê°ì§€: ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ì€ compression_ratio
for segment in result.segments:
    if segment.compression_ratio > 2.4:
        print(f"ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì„¸ê·¸ë¨¼íŠ¸: {segment.text}")
```

### ğŸ“‹ í™˜ê° ì²´í¬ë¦¬ìŠ¤íŠ¸

| ì¦ìƒ | í•´ê²°ì±… |
|------|--------|
| "Thanks for watching" ë“± | VAD í™œì„±í™” |
| ê°™ì€ ë¬¸ì¥ ë°˜ë³µ | `condition_on_previous_text=False` |
| ì¹¨ë¬µì—ì„œ í…ìŠ¤íŠ¸ ìƒì„± | `suppress_silence=True` |
| ë°°ê²½ ìŒì•…ì—ì„œ í™˜ê° | Demucs ë³´ì»¬ ë¶„ë¦¬ |
| ê¸´ ì¹¨ë¬µ í›„ í™˜ê° | ì˜¤ë””ì˜¤ ë¶„í•  ì²˜ë¦¬ |

---

## 13. ì‹¤ì „ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### âŒ ë¬¸ì œ 1: CUDA out of memory

```python
# í•´ê²°ì±… 1: int8 ì–‘ìí™”
model = stable_whisper.load_model('large-v3', device='cuda')
# ë˜ëŠ”
model = WhisperModel("large-v3", device="cuda", compute_type="int8")

# í•´ê²°ì±… 2: ë” ì‘ì€ ëª¨ë¸
model = stable_whisper.load_model('medium', device='cuda')

# í•´ê²°ì±… 3: CPU ì˜¤í”„ë¡œë“œ
model = stable_whisper.load_model('large-v3', device='cuda', cpu_preload=True)
```

### âŒ ë¬¸ì œ 2: íƒ€ì„ìŠ¤íƒ¬í”„ ì˜¤ì°¨

```python
# í•´ê²°ì±…: VAD + ì„¸ê·¸ë¨¼íŠ¸ ì¬ê·¸ë£¹í™”
result = model.transcribe(
    audio,
    vad=True,
    regroup=True,
)

# ë˜ëŠ” ìˆ˜ë™ ì¡°ì •
result.split_by_punctuation([('.', ' '), 'ã€‚', '?', 'ï¼Ÿ'])
result.split_by_gap(0.5)
result.merge_by_gap(0.15, max_words=3)
```

### âŒ ë¬¸ì œ 3: ì¼ë³¸ì–´ ì¸ì‹ ë¶ˆëŸ‰

```python
# í•´ê²°ì±… 1: ì–¸ì–´ ëª…ì‹œ
result = model.transcribe(audio, language='ja')

# í•´ê²°ì±… 2: ì´ˆê¸° í”„ë¡¬í”„íŠ¸
result = model.transcribe(
    audio, 
    language='ja',
    initial_prompt="ä»¥ä¸‹ã¯æ—¥æœ¬èªã®æ­Œè©ã§ã™ã€‚"
)

# í•´ê²°ì±… 3: ë³´ì»¬ ë¶„ë¦¬
result = model.transcribe(audio, language='ja', denoiser='demucs')
```

### âŒ ë¬¸ì œ 4: ê°€ì‚¬ì™€ ì‹±í¬ ë¶ˆì¼ì¹˜

```python
# í•´ê²°ì±…: align() ëŒ€ì‹  transcribe() í›„ ìˆ˜ë™ ë§¤ì¹­

# 1ë‹¨ê³„: ì „ì‚¬
result = model.transcribe(audio, language='ja')

# 2ë‹¨ê³„: ê²°ê³¼ ê²€í†  ë° ìˆ˜ì •
for segment in result.segments:
    print(f"[{segment.start:.2f}s] {segment.text}")

# 3ë‹¨ê³„: í•„ìš”ì‹œ ê°€ì‚¬ íŒŒì¼ê³¼ ë¹„êµ/ìˆ˜ì •
```

---

## 14. ì„±ëŠ¥ ìµœì í™” íŒ

### âš¡ GPU ë©”ëª¨ë¦¬ ìµœì í™”

```python
import torch

# ì²˜ë¦¬ ì „ ìºì‹œ ì •ë¦¬
torch.cuda.empty_cache()

# ë°°ì¹˜ ì²˜ë¦¬ì‹œ ëª¨ë¸ ì¬ì‚¬ìš©
model = stable_whisper.load_model('large-v3', device='cuda')

for song in songs:
    result = model.align(song['audio'], song['lyrics'], language='ja')
    # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
    result.save_as_json(f"cache/{song['name']}.json")

# ì™„ë£Œ í›„ ì •ë¦¬
del model
torch.cuda.empty_cache()
```

### âš¡ ë°°ì¹˜ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸

```python
import stable_whisper
from pathlib import Path
import json

def batch_sync(songs_dir, lyrics_dir, output_dir):
    model = stable_whisper.load_model('large-v3', device='cuda')
    
    for audio_path in Path(songs_dir).glob('*.mp3'):
        name = audio_path.stem
        lyrics_path = Path(lyrics_dir) / f"{name}.txt"
        output_path = Path(output_dir) / f"{name}.lrc"
        
        if not lyrics_path.exists():
            print(f"âš ï¸ ê°€ì‚¬ ì—†ìŒ: {name}")
            continue
            
        if output_path.exists():
            print(f"â­ï¸ ìŠ¤í‚µ (ì´ë¯¸ ì¡´ì¬): {name}")
            continue
        
        print(f"ğŸµ ì²˜ë¦¬ ì¤‘: {name}")
        
        lyrics = lyrics_path.read_text(encoding='utf-8')
        result = model.align(str(audio_path), lyrics, language='ja')
        result.to_srt_vtt(str(output_path), word_level=False)
        
        print(f"âœ… ì™„ë£Œ: {output_path}")
    
    del model
    
if __name__ == '__main__':
    batch_sync('songs/', 'lyrics/', 'output/')
```

---

## ğŸ“š ì¶”ê°€ ì°¸ê³  ìë£Œ

### í•™ìˆ  ë…¼ë¬¸
- [WhisperX: Time-Accurate Speech Transcription](https://arxiv.org/abs/2303.00747)
- [Investigation of Whisper ASR Hallucinations](https://arxiv.org/html/2501.11378v1)
- [Whisper Has an Internal Word Aligner](https://arxiv.org/html/2509.09987v1)

### ìœ ìš©í•œ GitHub ì €ì¥ì†Œ
- [EtienneAb3d/WhisperHallu](https://github.com/EtienneAb3d/WhisperHallu) - í™˜ê° ë°©ì§€
- [mikezzb/lyrics-sync](https://github.com/mikezzb/lyrics-sync) - ê°€ì‚¬ ì‹±í¬ íŒŒì´í”„ë¼ì¸
- [beveradb/lyrics-transcriber](https://pypi.org/project/lyrics-transcriber/) - ì¹´ë¼ì˜¤ì¼€ LRC ìƒì„±

### ì¼ë³¸ì–´ íŠ¹í™”
- [kotoba-tech/kotoba-whisper](https://huggingface.co/kotoba-tech/kotoba-whisper-v1.1) - ì¼ë³¸ì–´ ìµœì í™” Whisper

---

*ë¬¸ì„œ ì‘ì„±ì¼: 2025ë…„ 12ì›” 28ì¼*
*ê²€ìƒ‰ ê¸°ë°˜ ìµœì‹  ì •ë³´ ì¢…í•©*
