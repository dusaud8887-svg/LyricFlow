# ğŸµ í˜¸ì‹œë§ˆì¹˜ ìŠ¤ì´ì„¸ì´ ê°€ì‚¬ ì‹±í¬ í”„ë¡œì íŠ¸ (ìµœê³ í’ˆì§ˆ)

## ğŸ¯ í”„ë¡œì íŠ¸ ì„¤ì •

**ëŒ€ìƒ**: í˜¸ì‹œë§ˆì¹˜ ìŠ¤ì´ì„¸ì´ (æ˜Ÿè¡—ã™ã„ã›ã„) ë…¸ë˜  
**ëª¨ë¸**: `large-v3` (ìµœê³  í’ˆì§ˆ, 2.9GB)  
**GPU**: RTX 3070 Ti (CUDA ì§€ì›) â†’ 10ë°° ë¹ ë¥¸ ì²˜ë¦¬  
**ì–¸ì–´**: ì¼ë³¸ì–´ (`language='ja'`)

---

## âš™ï¸ ìµœì  ì„¤ì •

### RTX 3070 Ti ì‚¬ì–‘ í™•ì¸
- **VRAM**: 8GB â†’ large-v3 ëª¨ë¸ ì™„ë²½ ì§€ì› âœ…
- **CUDA**: ì„¤ì¹˜ë¨ â†’ GPU ê°€ì† ìë™ í™œìš© âœ…
- **ì˜ˆìƒ ì†ë„**: 3ë¶„ ê³¡ ê¸°ì¤€ **10-15ì´ˆ** ì²˜ë¦¬

### ëª¨ë¸ ì„ íƒ
```python
# ìµœê³  í’ˆì§ˆ ëª¨ë¸
model = stable_whisper.load_model('large-v3', device='cuda')
```

| í•­ëª© | ì‚¬ì–‘ |
|------|------|
| ëª¨ë¸ í¬ê¸° | 2.9GB |
| ì •í™•ë„ | 98%+ (ì¼ë³¸ì–´) |
| ì²˜ë¦¬ ì†ë„ | 10-15ì´ˆ/ê³¡ (3ë¶„ ê¸°ì¤€) |
| VRAM ì‚¬ìš© | ~4-5GB |

---

## ğŸ“ íŒŒì¼ êµ¬ì¡° (í˜¸ì‹œë§ˆì¹˜ ìŠ¤ì´ì„¸ì´)

```
suisei_lyrics/
â”œâ”€â”€ songs/
â”‚   â”œâ”€â”€ stellar_stellar.mp3
â”‚   â”œâ”€â”€ template.mp3
â”‚   â”œâ”€â”€ ghost.mp3
â”‚   â””â”€â”€ ...
â”œâ”€â”€ lyrics/
â”‚   â”œâ”€â”€ stellar_stellar.txt      # ì¼ë³¸ì–´ ê°€ì‚¬ (UTF-8)
â”‚   â”œâ”€â”€ template.txt
â”‚   â”œâ”€â”€ ghost.txt
â”‚   â””â”€â”€ ...
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ stellar_stellar.lrc
â”‚   â””â”€â”€ ...
â””â”€â”€ sync_suisei.py
```

---

## ğŸ’» ìµœì í™” ìŠ¤í¬ë¦½íŠ¸

### ì™„ì „ ìë™í™” ë²„ì „ (GPU ìµœì í™”)

```python
"""
í˜¸ì‹œë§ˆì¹˜ ìŠ¤ì´ì„¸ì´ ê°€ì‚¬ ì‹±í¬ (GPU ìµœì í™”)
RTX 3070 Ti + large-v3 ëª¨ë¸
"""
import stable_whisper
from pathlib import Path
import time

def sync_suisei_songs():
    # GPU í™•ì¸
    import torch
    if not torch.cuda.is_available():
        print("âš ï¸ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    gpu_name = torch.cuda.get_device_name(0)
    print(f"âœ… GPU ê°ì§€: {gpu_name}")
    print(f"âœ… VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\n")
    
    # ìµœê³  í’ˆì§ˆ ëª¨ë¸ ë¡œë“œ (GPU)
    print("ğŸ”„ large-v3 ëª¨ë¸ ë¡œë”© ì¤‘... (ì²« ì‹¤í–‰ì‹œ 2.9GB ë‹¤ìš´ë¡œë“œ)")
    model = stable_whisper.load_model('large-v3', device='cuda')
    print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\n")
    
    # ë…¸ë˜ ëª©ë¡ (íŒŒì¼ëª…ë§Œ í™•ì¥ì ì œì™¸)
    songs = [
        'stellar_stellar',
        'template',
        'ghost',
        # ... ì¶”ê°€ ê³¡ë“¤
    ]
    
    total_start = time.time()
    
    for i, song in enumerate(songs, 1):
        print(f"[{i}/{len(songs)}] ì²˜ë¦¬ ì¤‘: {song}")
        print("-" * 60)
        
        mp3_path = f'songs/{song}.mp3'
        lyrics_path = f'lyrics/{song}.txt'
        output_path = f'output/{song}.lrc'
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not Path(mp3_path).exists():
            print(f"âŒ MP3 íŒŒì¼ ì—†ìŒ: {mp3_path}\n")
            continue
        if not Path(lyrics_path).exists():
            print(f"âŒ ê°€ì‚¬ íŒŒì¼ ì—†ìŒ: {lyrics_path}\n")
            continue
        
        try:
            # ê°€ì‚¬ ì½ê¸°
            with open(lyrics_path, 'r', encoding='utf-8') as f:
                lyrics = f.read().strip()
            
            lines = len([l for l in lyrics.split('\n') if l.strip()])
            print(f"ğŸ“ ê°€ì‚¬ ë¼ì¸: {lines}ê°œ")
            
            # GPU ê°€ì‚¬ ì •ë ¬ (ì¼ë³¸ì–´)
            start = time.time()
            result = model.align(
                mp3_path, 
                lyrics, 
                language='ja'  # ì¼ë³¸ì–´
            )
            elapsed = time.time() - start
            
            # LRC ì €ì¥
            result.to_srt_vtt(output_path, word_level=False)
            
            print(f"âœ… ì™„ë£Œ: {output_path}")
            print(f"â±ï¸ ì†Œìš”ì‹œê°„: {elapsed:.1f}ì´ˆ\n")
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}\n")
            continue
    
    total_time = time.time() - total_start
    print("=" * 60)
    print(f"âœ… ì „ì²´ ì™„ë£Œ! ì´ ì†Œìš”ì‹œê°„: {total_time/60:.1f}ë¶„")
    print("=" * 60)

if __name__ == '__main__':
    sync_suisei_songs()
```

---

## ğŸš€ ì‹¤í–‰ ë‹¨ê³„ë³„ ê°€ì´ë“œ

### Step 1: í™˜ê²½ ì¤€ë¹„
```bash
# 1. stable-ts ì„¤ì¹˜
pip install stable-ts

# 2. PyTorch CUDA í™•ì¸ (ì´ë¯¸ ì„¤ì¹˜ë¨)
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
# ì¶œë ¥: CUDA: True
```

### Step 2: í´ë” ìƒì„±
```bash
mkdir suisei_lyrics
cd suisei_lyrics
mkdir songs lyrics output
```

### Step 3: íŒŒì¼ ë°°ì¹˜
```
1. MP3 íŒŒì¼ë“¤ â†’ songs/ í´ë”
2. ê°€ì‚¬ í…ìŠ¤íŠ¸ë“¤ â†’ lyrics/ í´ë” (UTF-8 í•„ìˆ˜!)
3. íŒŒì¼ëª… ë§¤ì¹­ í™•ì¸
```

### Step 4: ì²« ì‹¤í–‰ (í…ŒìŠ¤íŠ¸)
```python
# test_one.py - 1ê³¡ìœ¼ë¡œ ë¨¼ì € í…ŒìŠ¤íŠ¸
import stable_whisper
import torch

print(f"GPU: {torch.cuda.get_device_name(0)}")

model = stable_whisper.load_model('large-v3', device='cuda')

with open('lyrics/stellar_stellar.txt', 'r', encoding='utf-8') as f:
    lyrics = f.read()

result = model.align('songs/stellar_stellar.mp3', lyrics, language='ja')
result.to_srt_vtt('output/stellar_stellar.lrc', word_level=False)

print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
```

### Step 5: ë°°ì¹˜ ì‹¤í–‰
```bash
python sync_suisei.py
```

---

## âš¡ GPU ì„±ëŠ¥ ì˜ˆì¸¡

### RTX 3070 Ti ì²˜ë¦¬ ì†ë„
| ê³¡ ê¸¸ì´ | CPU (large-v3) | GPU (3070 Ti) |
|---------|----------------|---------------|
| 3ë¶„ | ~2-3ë¶„ | **10-15ì´ˆ** |
| 4ë¶„ | ~3-4ë¶„ | **15-20ì´ˆ** |
| 5ë¶„ | ~4-5ë¶„ | **20-25ì´ˆ** |

### 10ê³¡ ì²˜ë¦¬ ì˜ˆìƒ
- **ì „ì²´ ì‹œê°„**: ì•½ **2-3ë¶„** (ì²« ì‹¤í–‰ ì œì™¸)
- **ì²« ì‹¤í–‰**: +3ë¶„ (ëª¨ë¸ ë‹¤ìš´ë¡œë“œ 2.9GB)
- **GPU í™œìš©ë„**: ~80-90%
- **VRAM ì‚¬ìš©**: ~4-5GB / 8GB

---

## ğŸŒ ì¼ë³¸ì–´ ìµœì í™”

### ì–¸ì–´ ì„¤ì •
```python
result = model.align(
    audio_file, 
    lyrics, 
    language='ja'  # ì¼ë³¸ì–´ í•„ìˆ˜!
)
```

### ê°€ì‚¬ íŒŒì¼ ì£¼ì˜ì‚¬í•­
```text
âœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ (lyrics.txt):
è¡Œã“ã†ã€€ã“ã®å£°ã«å°ã‹ã‚Œ
ä»Šæ—¥ã‚‚ã¾ãŸä¸€æ­©ãšã¤
å¤¢è¦‹ãŸå ´æ‰€ã¸

âŒ ì˜ëª»ëœ ì˜ˆì‹œ:
- ë¡œë§ˆì í‘œê¸° (iko kono koe ni...)  â† ì•ˆ ë¨!
- ë²ˆì—­ëœ í•œê¸€/ì˜ì–´ â† ì•ˆ ë¨!
- ì›ë³¸ ì¼ë³¸ì–´ë§Œ ì‚¬ìš©!
```

---

## ğŸ”§ ê³ ê¸‰ ì˜µì…˜ (ì„ íƒì‚¬í•­)

### ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ (Enhanced LRC)
```python
# ë¼ì¸ë³„ (ì¼ë°˜)
result.to_srt_vtt('output.lrc', word_level=False)

# ë‹¨ì–´ë³„ (ë” ì •ë°€ - ì¹´ë¼ì˜¤ì¼€ìš©)
result.to_srt_vtt('output_word.lrc', word_level=True)
```

### GPU ë©”ëª¨ë¦¬ ìµœì í™” (8GB ì¶©ë¶„í•˜ì§€ë§Œ)
```python
# ë°°ì¹˜ ì²˜ë¦¬ì‹œ ëª¨ë¸ í•œ ë²ˆë§Œ ë¡œë“œ
model = stable_whisper.load_model('large-v3', device='cuda')

for song in songs:
    result = model.align(...)  # ëª¨ë¸ ì¬ì‚¬ìš©
    
# ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
del model
torch.cuda.empty_cache()
```

---

## ğŸ“Š í’ˆì§ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] GPU ì¸ì‹ í™•ì¸ (`torch.cuda.is_available()`)
- [ ] ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ (2.9GB)
- [ ] ì²« ê³¡ í…ŒìŠ¤íŠ¸ ì„±ê³µ
- [ ] LRC íŒŒì¼ ì¬ìƒ í™•ì¸ (ìŒì•… í”Œë ˆì´ì–´)
- [ ] íƒ€ì„ìŠ¤íƒ¬í”„ ì •í™•ë„ í™•ì¸ (Â±0.3ì´ˆ)
- [ ] ì¼ë³¸ì–´ í…ìŠ¤íŠ¸ ê¹¨ì§ ì—†ìŒ
- [ ] ì „ì²´ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ

---

## ğŸµ ì˜ˆìƒ LRC ê²°ê³¼ (ìƒ˜í”Œ)

```lrc
[00:15.23] è¡Œã“ã†ã€€ã“ã®å£°ã«å°ã‹ã‚Œ
[00:19.45] ä»Šæ—¥ã‚‚ã¾ãŸä¸€æ­©ãšã¤
[00:23.67] å¤¢è¦‹ãŸå ´æ‰€ã¸
[00:27.89] è¼ãæœªæ¥ã‚’ä¿¡ã˜ã¦
```

**í’ˆì§ˆ**: large-v3 ëª¨ë¸ â†’ **Â±0.2-0.3ì´ˆ ì •í™•ë„**

---

## ğŸ’¡ ìµœì¢… ì‹¤í–‰ ê³„íš

1. **í™˜ê²½ í™•ì¸** (5ë¶„)
   - GPU, CUDA í™•ì¸
   - stable-ts ì„¤ì¹˜

2. **íŒŒì¼ ì¤€ë¹„** (10ë¶„)
   - í´ë” ìƒì„±
   - MP3, ê°€ì‚¬ íŒŒì¼ ë°°ì¹˜

3. **í…ŒìŠ¤íŠ¸** (5ë¶„)
   - 1ê³¡ìœ¼ë¡œ í’ˆì§ˆ í™•ì¸

4. **ë°°ì¹˜ ì‹¤í–‰** (2-3ë¶„)
   - ì „ì²´ ê³¡ ìë™ ì²˜ë¦¬

**ì´ ì†Œìš”ì‹œê°„**: ì•½ **30ë¶„** (10ê³¡ ê¸°ì¤€)

ì¤€ë¹„ ì™„ë£Œë˜ë©´ ì‹œì‘í•˜ì‹œë©´ ë©ë‹ˆë‹¤! ğŸš€